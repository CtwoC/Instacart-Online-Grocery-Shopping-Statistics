---
title: "model"
author: "Zichu"
date: "11/17/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r basicfcn, include=F}
# can add quietly=T option to the require() function
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
```

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
library("dplyr")
```


```{r}
features <- read.csv("../DataSet/features.csv")
features <- subset(features,user_id<=10000)
```

1.try PCA and PCA regression
```{r}
dfpca <- features[c(4:10,12:21)]
pca <- prcomp(dfpca,scale=TRUE)
summary(pca)
```

```{r}
pr.var <- (pca$sdev^2)
pve <- pr.var/sum(pr.var)
cumsum(pve)
plot(cumsum(pve), xlab="Principal Component (non-standardized)", ylab ="Cumulative Proportion of Variance Explained",ylim=c(0,1),type="b")
```

13 components:0.994
14 components:1.000

PCA regression:
```{r}
loadPkg("pls")
pcr.fit1=pcr(ytrain~.,data=dfpca,scale=TRUE,validation ="CV")
summary(pcr.fit1)
```

```{r}
validationplot(pcr.fit1,val.type="R2")
```


2.logistic regression
#find that o.m and n.o.u are actually a same variable. Exclude o.m from the variables.
```{r}
shoplogit <- glm(ytrain ~ t.b + f.o.n + ror.pu + l4o + n.o.p + ror.p  + ror.pd + avg.p + n.o.u + n.p.u + avg.pou + d.m.o + t.m.o + ror.u + o.f, data=features,family="binomial")
summary(shoplogit)
```
n.o.p and d.m.o are not significant among all these variables


model evaluation:
```{r}
loadPkg("pROC")
features$predict1<- predict(shoplogit,type=c("response"))
h1 <- roc(ytrain ~ predict1, data=features)
auc(h1)
plot(h1)
```

AUC=0.74<0.8

3.KNN
#split the whole data set to train set and test set
```{r}
set.seed(1)
shop_train_rows = sample(1:nrow(features),
                              round(0.8 * nrow(features), 0),  
                              replace = FALSE)


length(shop_train_rows) / nrow(features)

shop_train = features[shop_train_rows,c(4,6:10,12:20)] 
shop_train_label = features[shop_train_rows,"ytrain"]
shop_test = features[-shop_train_rows,c(4,6:10,12:20)] 
shop_test_label = features[-shop_train_rows,"ytrain"]

# Check the number of rows in each set.
nrow(shop_train)
nrow(shop_test)

```

#function of choosing k
```{r}
loadPkg("class")
chooseK = function(k, train_set, val_set, train_class, val_class){
  
  # Build knn with k neighbors considered.
  set.seed(1)
  class_knn = knn(train = train_set,    #<- training set cases
                  test = val_set,       #<- test set cases
                  cl = train_class,     #<- category for classification
                  k = k,                #<- number of neighbors considered
                  use.all = TRUE)       #<- control ties between class assignments
                                        #   If true, all distances equal to the kth 
                                        #   largest are included
  
  tab = table(class_knn, val_class)
  
  # Calculate the accuracy.
  cmk = confusionMatrix( factor(class_knn), reference = factor(shop_test_label) )
  cbind(k = k, accuracy = accu)
}
```

```{r}
#1nn
shop_1nn <- knn(train=shop_train,test=shop_test,cl=shop_train_label,k=1,use.all=TRUE)

```


```{r}
#choose the best k with a confusion Matrix table
loadPkg("caret") 
cmtable <- data.frame(matrix(ncol = 0, nrow = 11))
for (k in seq(1,21,by=2)){
  class_knn=knn(train = shop_train,    #<- training set cases
                  test = shop_test,       #<- test set cases
                  cl = shop_train_label,     #<- category for classification
                  k = k,                #<- number of neighbors considered
                  )  
  cm <- confusionMatrix( factor(class_knn), reference = factor(shop_test_label))
  cmtable<- cbind(cmtable,data.frame(cm$byClass))
}
cmtable <- data.frame(cmtable)
x <- c(paste0("k=", seq(1,21,by=2)))
colnames(cmtable) <- x
```

```{r}
#k=1,3,5
knn_different_k1 = sapply(seq(1, 5, by = 2),  
                         function(x) chooseK(x, 
                                             train_set = shop_train,
                                             val_set = shop_test,
                                             train_class = shop_train_label,
                                             val_class = shop_test_label))

```

```{r}
#k=7,9,11
knn_different_k2 = sapply(seq(7, 11, by = 2),  
                         function(x) chooseK(x, 
                                             train_set = shop_train,
                                             val_set = shop_test,
                                             train_class = shop_train_label,
                                             val_class = shop_test_label))

```

```{r}
#k=13,15,17
knn_different_k3 = sapply(seq(13, 17, by = 2),  
                         function(x) chooseK(x, 
                                             train_set = shop_train,
                                             val_set = shop_test,
                                             train_class = shop_train_label,
                                             val_class = shop_test_label))
```

```{r}
knn_different_k=cbind(knn_different_k1,knn_different_k2,knn_different_k3)
knn_different_k=data.frame(k=knn_different_k[1,],
                          accuracy=knn_k_accuracy[2,])
loadPkg("ggplot2")

ggplot(knn_different_k,
       aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3)
```


4.decision tree
```{r}
library("rpart")
shoptree <- rpart(ytrain ~ t.b + f.o.n + ror.pu + l4o + n.o.p + ror.p  + ror.pd + avg.p + n.o.u + n.p.u + avg.pou + d.m.o + t.m.o + ror.u + o.f, data=features, method="class",control=rpart.control(minbucket=20,cp=0.0001))
```

```{r}
summary(shoptree)
plot(shoptree, uniform=TRUE, main="Classification Tree")
text(shoptree, use.n=TRUE, all=TRUE, cex=.8)
```

```{r fancyplot}
loadPkg("rpart.plot")
rpart.plot(shoptree)
loadPkg("rattle") # For fancyRpartPlot (Trees) Answer "no" on installing from binary source
fancyRpartPlot(shoptree)

```

```{r}
features$predict2 <- predict(shoptree, type = "class")
```

model evaluation:
```{r, include=T,message=F}
loadPkg("caret") 
cm = confusionMatrix( factor(features$predict2), reference = factor(features$ytrain) )
print('Overall: ')
cm$overall
print('Class: ')
cm$byClass
```

random forest:
```{r}
library(randomForest)
shopforest <- randomForest(x=shop_train,y=as.factor(shop_train_label),xtest=shop_test,ytest=as.factor(shop_test_label),importance=T,ntree=100,max_depth=25,min_simples_leaf=5  )
```

ROC:
```{r}
library("pROC")
h2 <- roc(response = features$ytrain,predictor = predict(shopforest, type = "class")$posterior[,"1"])
auc(h2)
plot(h2)
```

